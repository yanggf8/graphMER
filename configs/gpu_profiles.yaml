# GPU Training Profiles
# Format: profile_name -> training parameters

406016G:
  description: "4GB GPU, 6 cores, 16GB RAM - Conservative profile"
  steps: 1000
  max_samples: 5000
  micro_batch_size: 4
  grad_accum_steps: 16
  save_every_steps: 200
  amp: true
  config: "configs/train_v2_gpu.yaml"

408032G:
  description: "8GB GPU, 8 cores, 32GB RAM - Balanced profile [PRODUCTION VALIDATED]"
  steps: 3000
  max_samples: 20000
  micro_batch_size: 6
  grad_accum_steps: 20
  save_every_steps: 250
  amp: true
  config: "configs/train_v2_gpu.yaml"
  # Validated: 51.8% loss reduction, 37.5% MLM accuracy, stable convergence

81664G:
  description: "16GB GPU, 16 cores, 64GB RAM - High-end profile"
  steps: 5000
  max_samples: 20000
  micro_batch_size: 8
  grad_accum_steps: 24
  save_every_steps: 500
  amp: true
  config: "configs/train_v2_gpu.yaml"

RTX3050_8G:
  description: "NVIDIA GeForce RTX 3050 (8GB) - AMP on, balanced for local training"
  steps: 2000
  max_samples: 12000
  micro_batch_size: 6
  grad_accum_steps: 20
  save_every_steps: 200
  amp: true
  config: "configs/train_v2_gpu.yaml"

M2_8C_16G:
  description: "Apple M2 (8 cores, 16GB RAM) - tuned for MPS with extended curriculum"
  steps: 3600
  max_samples: 20000
  micro_batch_size: 4
  grad_accum_steps: 24
  save_every_steps: 300
  amp: false
  config: "configs/train_mps.yaml"
  use_full_kg: true
  warmup_steps: 400
  clip_grad: 1.0
  mnm_weight_ramp: 900
  max_code_files: 120
